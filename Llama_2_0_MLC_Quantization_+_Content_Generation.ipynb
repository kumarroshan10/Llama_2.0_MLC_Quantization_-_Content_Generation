{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling Llama-2 with MLC-LLM in Python\n",
        "\n",
        "This notebook demonstrates how to compile a model via [MLC-LLM](https://github.com/mlc-ai/mlc-llm) with a Python API. The `mlc-llm` package allows you to compile model at any directory. (https://mlc.ai/mlc-llm/docs/compilation/compile_models.html#more-model-compile-commands)"
      ],
      "metadata": {
        "id": "ABn8o4hYujp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMA8yJTXjVK4",
        "outputId": "c8daecc3-e339-4dc2-daa8-fe8cce8261a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 12 08:24:36 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre --force-reinstall mlc-ai-nightly-cu118 mlc-chat-nightly-cu118 -f https://mlc.ai/wheels"
      ],
      "metadata": {
        "id": "buQYWuX4Dvqd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81036436-a09f-469f-a6ec-6a70838ce47e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly-cu118\n",
            "  Downloading https://github.com/mlc-ai/package/releases/download/v0.9.dev0/mlc_ai_nightly_cu118-0.12.dev1900-cp310-cp310-manylinux_2_28_x86_64.whl (544.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m544.7/544.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mlc-chat-nightly-cu118\n",
            "  Downloading https://github.com/mlc-ai/package/releases/download/v0.9.dev0/mlc_chat_nightly_cu118-0.1.dev669-cp310-cp310-manylinux_2_28_x86_64.whl (60.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting attrs (from mlc-ai-nightly-cu118)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle (from mlc-ai-nightly-cu118)\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
            "Collecting decorator (from mlc-ai-nightly-cu118)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting ml-dtypes (from mlc-ai-nightly-cu118)\n",
            "  Downloading ml_dtypes-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy (from mlc-ai-nightly-cu118)\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil (from mlc-ai-nightly-cu118)\n",
            "  Downloading psutil-5.9.6-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.6/283.6 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy (from mlc-ai-nightly-cu118)\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado (from mlc-ai-nightly-cu118)\n",
            "  Downloading tornado-6.4-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.4/435.4 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from mlc-ai-nightly-cu118)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting fastapi (from mlc-chat-nightly-cu118)\n",
            "  Downloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn (from mlc-chat-nightly-cu118)\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shortuuid (from mlc-chat-nightly-cu118)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting anyio<4.0.0,>=3.7.1 (from fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=7.0 (from uvicorn->mlc-chat-nightly-cu118)\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn->mlc-chat-nightly-cu118)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna>=2.8 (from anyio<4.0.0,>=3.7.1->fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio>=1.1 (from anyio<4.0.0,>=3.7.1->fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting exceptiongroup (from anyio<4.0.0,>=3.7.1->fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.5 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi->mlc-chat-nightly-cu118)\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, tornado, sniffio, shortuuid, psutil, numpy, idna, h11, exceptiongroup, decorator, cloudpickle, click, attrs, annotated-types, uvicorn, scipy, pydantic-core, ml-dtypes, anyio, starlette, pydantic, mlc-ai-nightly-cu118, fastapi, mlc-chat-nightly-cu118\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 6.3.2\n",
            "    Uninstalling tornado-6.3.2:\n",
            "      Successfully uninstalled tornado-6.3.2\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.0\n",
            "    Uninstalling sniffio-1.3.0:\n",
            "      Successfully uninstalled sniffio-1.3.0\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.6\n",
            "    Uninstalling idna-3.6:\n",
            "      Successfully uninstalled idna-3.6\n",
            "  Attempting uninstall: exceptiongroup\n",
            "    Found existing installation: exceptiongroup 1.2.0\n",
            "    Uninstalling exceptiongroup-1.2.0:\n",
            "      Successfully uninstalled exceptiongroup-1.2.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.2 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado==6.3.2, but you have tornado 6.4 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.1.1 which is incompatible.\n",
            "tensorflow 2.14.0 requires ml-dtypes==0.2.0, but you have ml-dtypes 0.3.1 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.6.0 anyio-3.7.1 attrs-23.1.0 click-8.1.7 cloudpickle-3.0.0 decorator-5.1.1 exceptiongroup-1.2.0 fastapi-0.105.0 h11-0.14.0 idna-3.6 ml-dtypes-0.3.1 mlc-ai-nightly-cu118-0.12.dev1900 mlc-chat-nightly-cu118-0.1.dev669 numpy-1.26.2 psutil-5.9.6 pydantic-2.5.2 pydantic-core-2.14.5 scipy-1.11.4 shortuuid-1.0.11 sniffio-1.3.0 starlette-0.27.0 tornado-6.4 typing-extensions-4.9.0 uvicorn-0.24.0.post1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "decorator",
                  "psutil",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recursive https://github.com/mlc-ai/mlc-llm.git"
      ],
      "metadata": {
        "id": "O5trBYo7xlJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fda868-a501-472e-a6b1-e7b3b53c133f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mlc-llm'...\n",
            "remote: Enumerating objects: 12280, done.\u001b[K\n",
            "remote: Counting objects: 100% (1644/1644), done.\u001b[K\n",
            "remote: Compressing objects: 100% (558/558), done.\u001b[K\n",
            "remote: Total 12280 (delta 1284), reused 1221 (delta 1085), pack-reused 10636\u001b[K\n",
            "Receiving objects: 100% (12280/12280), 23.65 MiB | 15.52 MiB/s, done.\n",
            "Resolving deltas: 100% (7946/7946), done.\n",
            "Submodule '3rdparty/argparse' (https://github.com/p-ranav/argparse) registered for path '3rdparty/argparse'\n",
            "Submodule '3rdparty/googletest' (https://github.com/google/googletest.git) registered for path '3rdparty/googletest'\n",
            "Submodule '3rdparty/tokenizers-cpp' (https://github.com/mlc-ai/tokenizers-cpp) registered for path '3rdparty/tokenizers-cpp'\n",
            "Submodule '3rdparty/tvm' (https://github.com/mlc-ai/relax.git) registered for path '3rdparty/tvm'\n",
            "Cloning into '/content/mlc-llm/3rdparty/argparse'...\n",
            "remote: Enumerating objects: 2822, done.        \n",
            "remote: Counting objects: 100% (2822/2822), done.        \n",
            "remote: Compressing objects: 100% (856/856), done.        \n",
            "remote: Total 2822 (delta 1541), reused 2724 (delta 1512), pack-reused 0        \n",
            "Receiving objects: 100% (2822/2822), 935.41 KiB | 3.73 MiB/s, done.\n",
            "Resolving deltas: 100% (1541/1541), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/googletest'...\n",
            "remote: Enumerating objects: 27056, done.        \n",
            "remote: Counting objects: 100% (95/95), done.        \n",
            "remote: Compressing objects: 100% (54/54), done.        \n",
            "remote: Total 27056 (delta 45), reused 65 (delta 36), pack-reused 26961        \n",
            "Receiving objects: 100% (27056/27056), 12.55 MiB | 15.75 MiB/s, done.\n",
            "Resolving deltas: 100% (20075/20075), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tokenizers-cpp'...\n",
            "remote: Enumerating objects: 139, done.        \n",
            "remote: Counting objects: 100% (31/31), done.        \n",
            "remote: Compressing objects: 100% (25/25), done.        \n",
            "remote: Total 139 (delta 16), reused 7 (delta 6), pack-reused 108        \n",
            "Receiving objects: 100% (139/139), 41.78 KiB | 167.00 KiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm'...\n",
            "remote: Enumerating objects: 193314, done.        \n",
            "remote: Counting objects: 100% (8574/8574), done.        \n",
            "remote: Compressing objects: 100% (706/706), done.        \n",
            "remote: Total 193314 (delta 7981), reused 8048 (delta 7858), pack-reused 184740        \n",
            "Receiving objects: 100% (193314/193314), 72.47 MiB | 14.55 MiB/s, done.\n",
            "Resolving deltas: 100% (150377/150377), done.\n",
            "Submodule path '3rdparty/argparse': checked out '557948f1236db9e27089959de837cc23de6c6bbd'\n",
            "Submodule path '3rdparty/googletest': checked out '45804691223635953f311cf31a10c632553bbfc3'\n",
            "Submodule path '3rdparty/tokenizers-cpp': checked out 'e47442f1aa766c27f17444218783ba1903890ba9'\n",
            "Submodule 'msgpack' (https://github.com/msgpack/msgpack-c) registered for path '3rdparty/tokenizers-cpp/msgpack'\n",
            "Submodule 'sentencepiece' (https://github.com/google/sentencepiece) registered for path '3rdparty/tokenizers-cpp/sentencepiece'\n",
            "Cloning into '/content/mlc-llm/3rdparty/tokenizers-cpp/msgpack'...\n",
            "remote: Enumerating objects: 30494, done.        \n",
            "remote: Counting objects: 100% (536/536), done.        \n",
            "remote: Compressing objects: 100% (238/238), done.        \n",
            "remote: Total 30494 (delta 290), reused 488 (delta 286), pack-reused 29958        \n",
            "Receiving objects: 100% (30494/30494), 94.28 MiB | 13.41 MiB/s, done.\n",
            "Resolving deltas: 100% (19774/19774), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tokenizers-cpp/sentencepiece'...\n",
            "remote: Enumerating objects: 4841, done.        \n",
            "remote: Counting objects: 100% (1873/1873), done.        \n",
            "remote: Compressing objects: 100% (206/206), done.        \n",
            "remote: Total 4841 (delta 1692), reused 1677 (delta 1666), pack-reused 2968        \n",
            "Receiving objects: 100% (4841/4841), 26.68 MiB | 10.63 MiB/s, done.\n",
            "Resolving deltas: 100% (3345/3345), done.\n",
            "Submodule path '3rdparty/tokenizers-cpp/msgpack': checked out '8c602e8579c7e7d65d6f9c6703c9699db3fb0488'\n",
            "Submodule path '3rdparty/tokenizers-cpp/sentencepiece': checked out 'f2219b53e24ff5deee4cacdc2d0ca3074e529a07'\n",
            "Submodule path '3rdparty/tvm': checked out '05a6c082d485462a159ad1b7f423d064fc5ec788'\n",
            "Submodule '3rdparty/OpenCL-Headers' (https://github.com/KhronosGroup/OpenCL-Headers.git) registered for path '3rdparty/tvm/3rdparty/OpenCL-Headers'\n",
            "Submodule '3rdparty/cnpy' (https://github.com/rogersce/cnpy.git) registered for path '3rdparty/tvm/3rdparty/cnpy'\n",
            "Submodule '3rdparty/cutlass' (https://github.com/NVIDIA/cutlass.git) registered for path '3rdparty/tvm/3rdparty/cutlass'\n",
            "Submodule '3rdparty/cutlass_fpA_intB_gemm' (https://github.com/tlc-pack/cutlass_fpA_intB_gemm) registered for path '3rdparty/tvm/3rdparty/cutlass_fpA_intB_gemm'\n",
            "Submodule 'dlpack' (https://github.com/dmlc/dlpack.git) registered for path '3rdparty/tvm/3rdparty/dlpack'\n",
            "Submodule 'dmlc-core' (https://github.com/dmlc/dmlc-core.git) registered for path '3rdparty/tvm/3rdparty/dmlc-core'\n",
            "Submodule '3rdparty/flashinfer' (https://github.com/flashinfer-ai/flashinfer.git) registered for path '3rdparty/tvm/3rdparty/flashinfer'\n",
            "Submodule '3rdparty/libbacktrace' (https://github.com/tlc-pack/libbacktrace.git) registered for path '3rdparty/tvm/3rdparty/libbacktrace'\n",
            "Submodule '3rdparty/libflash_attn' (https://github.com/tlc-pack/libflash_attn) registered for path '3rdparty/tvm/3rdparty/libflash_attn'\n",
            "Submodule '3rdparty/rang' (https://github.com/agauniyal/rang.git) registered for path '3rdparty/tvm/3rdparty/rang'\n",
            "Submodule '3rdparty/vta-hw' (https://github.com/apache/tvm-vta.git) registered for path '3rdparty/tvm/3rdparty/vta-hw'\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/OpenCL-Headers'...\n",
            "remote: Enumerating objects: 1320, done.        \n",
            "remote: Counting objects: 100% (343/343), done.        \n",
            "remote: Compressing objects: 100% (136/136), done.        \n",
            "remote: Total 1320 (delta 276), reused 232 (delta 203), pack-reused 977        \n",
            "Receiving objects: 100% (1320/1320), 747.02 KiB | 20.19 MiB/s, done.\n",
            "Resolving deltas: 100% (860/860), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/cnpy'...\n",
            "remote: Enumerating objects: 164, done.        \n",
            "remote: Total 164 (delta 0), reused 0 (delta 0), pack-reused 164        \n",
            "Receiving objects: 100% (164/164), 52.32 KiB | 17.44 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/cutlass'...\n",
            "remote: Enumerating objects: 23006, done.        \n",
            "remote: Counting objects: 100% (6023/6023), done.        \n",
            "remote: Compressing objects: 100% (1025/1025), done.        \n",
            "remote: Total 23006 (delta 5263), reused 5325 (delta 4984), pack-reused 16983        \n",
            "Receiving objects: 100% (23006/23006), 32.04 MiB | 12.47 MiB/s, done.\n",
            "Resolving deltas: 100% (17129/17129), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/cutlass_fpA_intB_gemm'...\n",
            "remote: Enumerating objects: 476, done.        \n",
            "remote: Counting objects: 100% (154/154), done.        \n",
            "remote: Compressing objects: 100% (36/36), done.        \n",
            "remote: Total 476 (delta 139), reused 119 (delta 118), pack-reused 322        \n",
            "Receiving objects: 100% (476/476), 211.99 KiB | 16.31 MiB/s, done.\n",
            "Resolving deltas: 100% (294/294), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/dlpack'...\n",
            "remote: Enumerating objects: 462, done.        \n",
            "remote: Counting objects: 100% (99/99), done.        \n",
            "remote: Compressing objects: 100% (40/40), done.        \n",
            "remote: Total 462 (delta 74), reused 69 (delta 59), pack-reused 363        \n",
            "Receiving objects: 100% (462/462), 1.70 MiB | 6.14 MiB/s, done.\n",
            "Resolving deltas: 100% (162/162), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/dmlc-core'...\n",
            "remote: Enumerating objects: 6334, done.        \n",
            "remote: Counting objects: 100% (198/198), done.        \n",
            "remote: Compressing objects: 100% (139/139), done.        \n",
            "remote: Total 6334 (delta 87), reused 108 (delta 38), pack-reused 6136        \n",
            "Receiving objects: 100% (6334/6334), 1.71 MiB | 2.33 MiB/s, done.\n",
            "Resolving deltas: 100% (3833/3833), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/flashinfer'...\n",
            "remote: Enumerating objects: 1906, done.        \n",
            "remote: Counting objects: 100% (291/291), done.        \n",
            "remote: Compressing objects: 100% (104/104), done.        \n",
            "remote: Total 1906 (delta 225), reused 228 (delta 187), pack-reused 1615        \n",
            "Receiving objects: 100% (1906/1906), 508.00 KiB | 16.93 MiB/s, done.\n",
            "Resolving deltas: 100% (1163/1163), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/libbacktrace'...\n",
            "remote: Enumerating objects: 459, done.        \n",
            "remote: Counting objects: 100% (311/311), done.        \n",
            "remote: Compressing objects: 100% (36/36), done.        \n",
            "remote: Total 459 (delta 285), reused 275 (delta 275), pack-reused 148        \n",
            "Receiving objects: 100% (459/459), 1.03 MiB | 4.13 MiB/s, done.\n",
            "Resolving deltas: 100% (341/341), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/libflash_attn'...\n",
            "remote: Enumerating objects: 148, done.        \n",
            "remote: Counting objects: 100% (148/148), done.        \n",
            "remote: Compressing objects: 100% (56/56), done.        \n",
            "remote: Total 148 (delta 97), reused 134 (delta 87), pack-reused 0        \n",
            "Receiving objects: 100% (148/148), 46.36 KiB | 11.59 MiB/s, done.\n",
            "Resolving deltas: 100% (97/97), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/rang'...\n",
            "remote: Enumerating objects: 735, done.        \n",
            "remote: Counting objects: 100% (31/31), done.        \n",
            "remote: Compressing objects: 100% (27/27), done.        \n",
            "remote: Total 735 (delta 9), reused 15 (delta 3), pack-reused 704        \n",
            "Receiving objects: 100% (735/735), 265.43 KiB | 15.61 MiB/s, done.\n",
            "Resolving deltas: 100% (371/371), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/vta-hw'...\n",
            "remote: Enumerating objects: 3312, done.        \n",
            "remote: Counting objects: 100% (328/328), done.        \n",
            "remote: Compressing objects: 100% (137/137), done.        \n",
            "remote: Total 3312 (delta 256), reused 191 (delta 191), pack-reused 2984        \n",
            "Receiving objects: 100% (3312/3312), 1.43 MiB | 20.92 MiB/s, done.\n",
            "Resolving deltas: 100% (1443/1443), done.\n",
            "Submodule path '3rdparty/tvm/3rdparty/OpenCL-Headers': checked out 'b590a6bfe034ea3a418b7b523e3490956bcb367a'\n",
            "Submodule path '3rdparty/tvm/3rdparty/cnpy': checked out '4e8810b1a8637695171ed346ce68f6984e585ef4'\n",
            "Submodule path '3rdparty/tvm/3rdparty/cutlass': checked out 'ff61a49dd1a728a96e9a8434ed408a2a52d73119'\n",
            "Submodule path '3rdparty/tvm/3rdparty/cutlass_fpA_intB_gemm': checked out 'ed951b046f89ddfd990af8d2482e3350bda2fec6'\n",
            "Submodule 'cutlass' (https://github.com/NVIDIA/cutlass) registered for path '3rdparty/tvm/3rdparty/cutlass_fpA_intB_gemm/cutlass'\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/cutlass_fpA_intB_gemm/cutlass'...\n",
            "remote: Enumerating objects: 23006, done.        \n",
            "remote: Counting objects: 100% (6023/6023), done.        \n",
            "remote: Compressing objects: 100% (1025/1025), done.        \n",
            "remote: Total 23006 (delta 5266), reused 5317 (delta 4984), pack-reused 16983        \n",
            "Receiving objects: 100% (23006/23006), 32.04 MiB | 15.69 MiB/s, done.\n",
            "Resolving deltas: 100% (17132/17132), done.\n",
            "Submodule path '3rdparty/tvm/3rdparty/cutlass_fpA_intB_gemm/cutlass': checked out 'cc85b64cf676c45f98a17e3a47c0aafcf817f088'\n",
            "Submodule path '3rdparty/tvm/3rdparty/dlpack': checked out 'e2bdd3bee8cb6501558042633fa59144cc8b7f5f'\n",
            "Submodule path '3rdparty/tvm/3rdparty/dmlc-core': checked out '09511cf9fe5ff103900a5eafb50870dc84cc17c8'\n",
            "Submodule path '3rdparty/tvm/3rdparty/flashinfer': checked out '11364ca4c3ce651dd544efff3225906fe15c5b8a'\n",
            "Submodule '3rdparty/googletest' (https://github.com/google/googletest.git) registered for path '3rdparty/tvm/3rdparty/flashinfer/3rdparty/googletest'\n",
            "Submodule '3rdparty/nvbench' (https://github.com/NVIDIA/nvbench.git) registered for path '3rdparty/tvm/3rdparty/flashinfer/3rdparty/nvbench'\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/flashinfer/3rdparty/googletest'...\n",
            "remote: Enumerating objects: 27056, done.        \n",
            "remote: Counting objects: 100% (95/95), done.        \n",
            "remote: Compressing objects: 100% (54/54), done.        \n",
            "remote: Total 27056 (delta 45), reused 65 (delta 36), pack-reused 26961        \n",
            "Receiving objects: 100% (27056/27056), 12.55 MiB | 9.79 MiB/s, done.\n",
            "Resolving deltas: 100% (20075/20075), done.\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/flashinfer/3rdparty/nvbench'...\n",
            "remote: Enumerating objects: 2748, done.        \n",
            "remote: Counting objects: 100% (1558/1558), done.        \n",
            "remote: Compressing objects: 100% (311/311), done.        \n",
            "remote: Total 2748 (delta 1330), reused 1275 (delta 1246), pack-reused 1190        \n",
            "Receiving objects: 100% (2748/2748), 752.45 KiB | 17.50 MiB/s, done.\n",
            "Resolving deltas: 100% (1909/1909), done.\n",
            "Submodule path '3rdparty/tvm/3rdparty/flashinfer/3rdparty/googletest': checked out '40412d85124f7c6f3d88454583c4633e5e10fc8c'\n",
            "Submodule path '3rdparty/tvm/3rdparty/flashinfer/3rdparty/nvbench': checked out 'f57aa9c993f4392a76650bc54513f571cd1128c9'\n",
            "Submodule path '3rdparty/tvm/3rdparty/libbacktrace': checked out '08f7c7e69f8ea61a0c4151359bc8023be8e9217b'\n",
            "Submodule path '3rdparty/tvm/3rdparty/libflash_attn': checked out '55d3603f741eb68e82640ff55ccea4b17dd8053e'\n",
            "Submodule 'cutlass' (https://github.com/NVIDIA/cutlass/) registered for path '3rdparty/tvm/3rdparty/libflash_attn/cutlass'\n",
            "Cloning into '/content/mlc-llm/3rdparty/tvm/3rdparty/libflash_attn/cutlass'...\n",
            "remote: Enumerating objects: 23006, done.        \n",
            "remote: Counting objects: 100% (6023/6023), done.        \n",
            "remote: Compressing objects: 100% (1025/1025), done.        \n",
            "remote: Total 23006 (delta 5263), reused 5325 (delta 4984), pack-reused 16983        \n",
            "Receiving objects: 100% (23006/23006), 32.04 MiB | 8.50 MiB/s, done.\n",
            "Resolving deltas: 100% (17129/17129), done.\n",
            "Submodule path '3rdparty/tvm/3rdparty/libflash_attn/cutlass': checked out 'e0aaa3c3b38db9a89c31f04fef91e92123ad5e2e'\n",
            "Submodule path '3rdparty/tvm/3rdparty/rang': checked out 'cabe04d6d6b05356fa8f9741704924788f0dd762'\n",
            "Submodule path '3rdparty/tvm/3rdparty/vta-hw': checked out '36a91576edf633479c78649e050f18dd2ddc8103'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then install `mlc-llm` as a package, so that we can use its functions outside of this directory."
      ],
      "metadata": {
        "id": "XiVKUPASeQ-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd mlc-llm && pip install -e . && cd -"
      ],
      "metadata": {
        "id": "loNmGvcfw40k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28b87e0-71d0-4b48-af97-704458de3800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/mlc-llm\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mlc-llm==0.1.dev677+g53e159b) (1.26.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mlc-llm==0.1.dev677+g53e159b) (2.1.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from mlc-llm==0.1.dev677+g53e159b) (4.35.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mlc-llm==0.1.dev677+g53e159b) (1.11.4)\n",
            "Collecting timm (from mlc-llm==0.1.dev677+g53e159b)\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm->mlc-llm==0.1.dev677+g53e159b) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm->mlc-llm==0.1.dev677+g53e159b) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm->mlc-llm==0.1.dev677+g53e159b) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm->mlc-llm==0.1.dev677+g53e159b) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->mlc-llm==0.1.dev677+g53e159b) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->mlc-llm==0.1.dev677+g53e159b) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->mlc-llm==0.1.dev677+g53e159b) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->mlc-llm==0.1.dev677+g53e159b) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->mlc-llm==0.1.dev677+g53e159b) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->mlc-llm==0.1.dev677+g53e159b) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->mlc-llm==0.1.dev677+g53e159b) (2.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->mlc-llm==0.1.dev677+g53e159b) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->mlc-llm==0.1.dev677+g53e159b) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->mlc-llm==0.1.dev677+g53e159b) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->mlc-llm==0.1.dev677+g53e159b) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->mlc-llm==0.1.dev677+g53e159b) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->mlc-llm==0.1.dev677+g53e159b) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mlc-llm==0.1.dev677+g53e159b) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mlc-llm==0.1.dev677+g53e159b) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mlc-llm==0.1.dev677+g53e159b) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->mlc-llm==0.1.dev677+g53e159b) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->mlc-llm==0.1.dev677+g53e159b) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm->mlc-llm==0.1.dev677+g53e159b) (9.4.0)\n",
            "Building wheels for collected packages: mlc-llm\n",
            "  Building editable for mlc-llm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mlc-llm: filename=mlc_llm-0.1.dev677+g53e159b-0.editable-py3-none-any.whl size=7384 sha256=b1604002aaabf8f62cd44d5b652ed95d0fab21e3a0442704315391ad504da26b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-w5zwte6z/wheels/60/f6/e4/f9ebad71d5663623c41caead0eb5663a07b045d94af8e40d00\n",
            "Successfully built mlc-llm\n",
            "Installing collected packages: timm, mlc-llm\n",
            "Successfully installed mlc-llm-0.1.dev677+g53e159b timm-0.9.12\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the Llama-2 model\n",
        "After setting up the environment, we need to download the model we will compile. In this case, it would be [Llama-2-7B-Chat](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf). Note: you do not need to download from this link, we will download the model for you in this notebook."
      ],
      "metadata": {
        "id": "uYxdGt28eaCi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To demonstrate that we can compile models using the `mlc-llm` model anywhere, we will create a separate directory to perform our work."
      ],
      "metadata": {
        "id": "HZxG6q2Ae2E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ./my_workspace && ls"
      ],
      "metadata": {
        "id": "X3v2WG2B0bPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f971397e-342a-4446-a331-710117126aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlc-llm  my_workspace  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd my_workspace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u0XJO1u8WYM",
        "outputId": "b92d1400-0341-4226-9bf6-3123a9e0609e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/my_workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to download the large weights, we'll have to use `git lfs`."
      ],
      "metadata": {
        "id": "Rax6nMTnj4NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install"
      ],
      "metadata": {
        "id": "SFmQ11_Lj6xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa5c2611-6760-4e74-a84f-de9b22c00338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will download the Llama-2 7B model from huggingface. Please first [request for access](https://huggingface.co/meta-llama) to Llama-2 weights (i.e. click [Llama-2 7B](https://huggingface.co/meta-llama/Llama-2-7b) and click the button to request access to the repo near the top of the model card information) from Meta using the email of your huggingface account. Then your huggingface account will have access to the model.\n",
        "\n",
        "Since this particular model requires permission, we would need to log in to our huggingface account. In order to \"log in\" to your hugginface account on Colab or notebooks, you would need to create an [Access Token](https://huggingface.co/settings/tokens), and copy the token into when prompted below.\n",
        "\n",
        "(Note: if the command appears to be taking a long time that most likely means the model is being downloaded, please check your filesystem to see if the directory `Llama-2-7b-chat-hf` has been created and is being populated)"
      ],
      "metadata": {
        "id": "tGp3V7EJfDyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the folder name\n",
        "folder_name = 'Llama-2-7b-chat-hf'\n",
        "\n",
        "# Specify the path where you want to create the folder\n",
        "workspace_path = '/content/my_workspace'  # Update this with your actual workspace path\n",
        "\n",
        "# Combine the workspace path and folder name to create the full path\n",
        "folder_path = os.path.join(workspace_path, folder_name)\n",
        "# Check if the folder already exists\n",
        "if not os.path.exists(folder_path):\n",
        "    # Create the folder if it doesn't exist\n",
        "    os.makedirs(folder_path)\n",
        "    print(f'Folder \"{folder_name}\" created in \"{workspace_path}\"')\n",
        "else:\n",
        "    print(f'Folder \"{folder_name}\" already exists in \"{workspace_path}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63je9pG9I3b3",
        "outputId": "8b7b35b4-9fcd-4093-8455-e72e51a5f103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder \"Llama-2-7b-chat-hf\" created in \"/content/my_workspace\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass, subprocess\n",
        "command = ['git', 'clone', f'https://{input(\"Enter your huggingface username:rahulrock12 \")}:{getpass.getpass(prompt=\"Huggingface CLI Access Token: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\")}@huggingface.co/meta-llama/Llama-2-7b-chat-hf']#TheBloke/Llama-2-70B-GPTQ\n",
        "p = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "command = []\n",
        "while p.poll() is None:\n",
        "  l = p.stderr.readline()\n",
        "  print(l.decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcrGSV7uZS5G",
        "outputId": "53bb5716-ffb1-439f-cf44-02a535b7d0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your huggingface username:rahulrock12 rahulrock12\n",
            "Huggingface CLI Access Token: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··········\n",
            "Cloning into 'Llama-2-7b-chat-hf'...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf Llama-2-7b-chat-hf/*.safetensors"
      ],
      "metadata": {
        "id": "Eaw4In763fur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile Llama2 with `mlc_llm`\n",
        "\n",
        "Finally, we can compile the model we just downloaded in Python."
      ],
      "metadata": {
        "id": "cHZJG2e5gGEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Need to restart runtime since notebooks cannot find the module right after installing\n",
        "# Simply run this cell, then run the next cells after runtime finishes restarting\n",
        "exit()"
      ],
      "metadata": {
        "id": "snyN3kKvFdTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After restarting the runtime of the notebook, first go into the workspace we created. After this cell, all code below will be in Python!"
      ],
      "metadata": {
        "id": "rXF2fU-7ktsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd my_workspace"
      ],
      "metadata": {
        "id": "HdFkznAkkr5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import `mlc_llm` that we installed using `pip -p`. `mlc_chat` and `tvm` are included in the nightly pacakges we installed earlier."
      ],
      "metadata": {
        "id": "nqrdTQFZkfNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlc_llm, mlc_chat, tvm"
      ],
      "metadata": {
        "id": "8pASvBuVDQms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_args = mlc_llm.BuildArgs(\n",
        "    model=\"Llama-2-7b-chat-hf\",\n",
        "    quantization=\"q4f16_1\",\n",
        "    target=\"cuda\")"
      ],
      "metadata": {
        "id": "ei3r2kenNqbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of `lib_path, model_path, chat_config_path = mlc_llm.build_model(build_args)` is given as a tuple of three paths.\n",
        "\n",
        "`lib_path` is the path to the specific binary that has been built.\n",
        "\n",
        "`model_path` is the path to the folder containing the compiled model parameters and other model specific configuration needed for other `mlc` modules.\n",
        "\n",
        "`chat_config_path` is the path to the specific `.json` configuration needed to have this model work with `mlc_chat`."
      ],
      "metadata": {
        "id": "F432oSPn2HSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lib_path, model_path, chat_config_path = mlc_llm.build_model(build_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMepfzs8O48L",
        "outputId": "11056fc7-b7c9-4353-a00f-f5a8a5f3d16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using path \"Llama-2-13b-chat-hf\" for model \"Llama-2-13b-chat-hf\"\n",
            "Target configured: cuda -keys=cuda,gpu -arch=sm_75 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n",
            "Automatically using target for weight quantization: cuda -keys=cuda,gpu -arch=sm_75 -max_num_threads=1024 -max_shared_memory_per_block=49152 -max_threads_per_block=1024 -registers_per_block=65536 -thread_warp_size=32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Get old param:   0%|          | 0/245 [00:00<?, ?tensors/s]\n",
            "Get old param:   0%|          | 1/245 [00:02<10:33,  2.60s/tensors]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start computing and quantizing weights... This may take a while.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Get old param:   1%|          | 2/245 [00:08<17:15,  4.26s/tensors]\n",
            "Get old param:   2%|▏         | 4/245 [00:52<1:02:30, 15.56s/tensors]\n",
            "Get old param:   2%|▏         | 5/245 [00:52<43:14, 10.81s/tensors]  \n",
            "Get old param:   3%|▎         | 7/245 [00:53<23:08,  5.83s/tensors]\n",
            "Set new param:   3%|▎         | 12/407 [00:53<15:07,  2.30s/tensors]\u001b[A\n",
            "Get old param:   4%|▍         | 11/245 [00:53<09:52,  2.53s/tensors]\n",
            "Get old param:   5%|▌         | 13/245 [00:53<07:09,  1.85s/tensors]\n",
            "Set new param:   5%|▌         | 22/407 [00:53<04:12,  1.52tensors/s]\u001b[A\n",
            "Get old param:   7%|▋         | 17/245 [00:54<03:57,  1.04s/tensors]\n",
            "Get old param:   8%|▊         | 19/245 [00:54<03:07,  1.20tensors/s]\n",
            "Set new param:   8%|▊         | 32/407 [00:54<01:34,  3.98tensors/s]\u001b[A\n",
            "Get old param:   9%|▉         | 23/245 [00:54<01:54,  1.93tensors/s]\n",
            "Get old param:  10%|█         | 25/245 [00:55<01:37,  2.27tensors/s]\n",
            "Set new param:  10%|█         | 42/407 [00:55<00:45,  8.05tensors/s]\u001b[A\n",
            "Get old param:  12%|█▏        | 29/245 [00:55<01:03,  3.41tensors/s]\n",
            "Get old param:  13%|█▎        | 31/245 [00:55<00:57,  3.72tensors/s]\n",
            "Set new param:  13%|█▎        | 51/407 [00:55<00:31, 11.29tensors/s]\u001b[A\n",
            "Get old param:  14%|█▍        | 35/245 [00:56<00:40,  5.22tensors/s]\n",
            "Get old param:  15%|█▌        | 37/245 [00:56<00:39,  5.26tensors/s]\n",
            "Set new param:  15%|█▌        | 62/407 [00:56<00:23, 14.62tensors/s]\u001b[A\n",
            "Get old param:  17%|█▋        | 41/245 [00:56<00:29,  6.96tensors/s]\n",
            "Get old param:  18%|█▊        | 43/245 [00:57<00:30,  6.53tensors/s]\n",
            "Set new param:  17%|█▋        | 71/407 [00:57<00:23, 14.57tensors/s]\u001b[A\n",
            "Get old param:  19%|█▉        | 47/245 [00:57<00:23,  8.28tensors/s]\n",
            "Get old param:  20%|██        | 49/245 [00:57<00:26,  7.46tensors/s]\n",
            "Set new param:  20%|█▉        | 81/407 [00:57<00:21, 15.17tensors/s]\u001b[A\n",
            "Get old param:  22%|██▏       | 53/245 [00:57<00:21,  9.13tensors/s]\n",
            "Get old param:  22%|██▏       | 55/245 [00:58<00:24,  7.90tensors/s]\n",
            "Set new param:  22%|██▏       | 91/407 [00:58<00:20, 15.14tensors/s]\u001b[A\n",
            "Get old param:  24%|██▍       | 59/245 [00:58<00:19,  9.57tensors/s]\n",
            "Get old param:  25%|██▍       | 61/245 [00:58<00:22,  8.04tensors/s]\n",
            "Set new param:  25%|██▍       | 101/407 [00:59<00:20, 14.91tensors/s]\u001b[A\n",
            "Get old param:  27%|██▋       | 65/245 [00:59<00:18,  9.72tensors/s]\n",
            "Get old param:  27%|██▋       | 67/245 [00:59<00:21,  8.26tensors/s]\n",
            "Set new param:  28%|██▊       | 112/407 [00:59<00:18, 16.09tensors/s]\u001b[A\n",
            "Get old param:  29%|██▉       | 71/245 [00:59<00:17,  9.92tensors/s]\n",
            "Get old param:  30%|██▉       | 73/245 [01:00<00:20,  8.44tensors/s]\n",
            "Set new param:  30%|██▉       | 122/407 [01:00<00:17, 16.22tensors/s]\u001b[A\n",
            "Get old param:  31%|███▏      | 77/245 [01:00<00:16, 10.05tensors/s]\n",
            "Get old param:  32%|███▏      | 79/245 [01:00<00:19,  8.47tensors/s]\n",
            "Set new param:  32%|███▏      | 131/407 [01:00<00:18, 15.11tensors/s]\u001b[A\n",
            "Get old param:  34%|███▍      | 83/245 [01:01<00:16, 10.09tensors/s]\n",
            "Get old param:  35%|███▍      | 85/245 [01:01<00:18,  8.49tensors/s]\n",
            "Set new param:  35%|███▍      | 142/407 [01:01<00:16, 16.24tensors/s]\u001b[A\n",
            "Get old param:  36%|███▋      | 89/245 [01:01<00:15, 10.12tensors/s]\n",
            "Get old param:  37%|███▋      | 91/245 [01:02<00:18,  8.50tensors/s]\n",
            "Set new param:  37%|███▋      | 152/407 [01:02<00:15, 16.13tensors/s]\u001b[A\n",
            "Set new param:  38%|███▊      | 154/407 [01:19<00:15, 16.13tensors/s]\u001b[A\n",
            "Get old param:  39%|███▉      | 95/245 [01:52<11:56,  4.78s/tensors]\n",
            "Get old param:  40%|███▉      | 97/245 [01:52<09:26,  3.83s/tensors]\n",
            "Set new param:  40%|███▉      | 161/407 [01:52<10:12,  2.49s/tensors]\u001b[A\n",
            "Get old param:  41%|████      | 101/245 [01:52<05:46,  2.41s/tensors]\n",
            "Get old param:  42%|████▏     | 103/245 [01:53<04:34,  1.93s/tensors]\n",
            "Set new param:  42%|████▏     | 171/407 [01:53<03:28,  1.13tensors/s]\u001b[A\n",
            "Get old param:  44%|████▎     | 107/245 [01:53<02:49,  1.23s/tensors]\n",
            "Get old param:  44%|████▍     | 109/245 [01:53<02:17,  1.01s/tensors]\n",
            "Set new param:  44%|████▍     | 181/407 [01:53<01:18,  2.89tensors/s]\u001b[A\n",
            "Get old param:  46%|████▌     | 113/245 [01:54<01:26,  1.53tensors/s]\n",
            "Get old param:  47%|████▋     | 115/245 [01:54<01:11,  1.81tensors/s]\n",
            "Set new param:  47%|████▋     | 192/407 [01:54<00:31,  6.73tensors/s]\u001b[A\n",
            "Get old param:  49%|████▊     | 119/245 [01:54<00:46,  2.70tensors/s]\n",
            "Get old param:  49%|████▉     | 121/245 [01:55<00:41,  3.01tensors/s]\n",
            "Set new param:  49%|████▉     | 201/407 [01:55<00:20, 10.03tensors/s]\u001b[A\n",
            "Get old param:  51%|█████     | 125/245 [01:55<00:27,  4.31tensors/s]\n",
            "Get old param:  52%|█████▏    | 127/245 [01:55<00:26,  4.50tensors/s]\n",
            "Set new param:  52%|█████▏    | 211/407 [01:55<00:15, 12.96tensors/s]\u001b[A\n",
            "Get old param:  53%|█████▎    | 131/245 [01:56<00:18,  6.09tensors/s]\n",
            "Get old param:  54%|█████▍    | 133/245 [01:56<00:18,  5.94tensors/s]\n",
            "Set new param:  54%|█████▍    | 221/407 [01:56<00:12, 14.52tensors/s]\u001b[A\n",
            "Get old param:  56%|█████▌    | 137/245 [01:56<00:14,  7.69tensors/s]\n",
            "Get old param:  57%|█████▋    | 139/245 [01:57<00:14,  7.08tensors/s]\n",
            "Set new param:  57%|█████▋    | 232/407 [01:57<00:10, 16.19tensors/s]\u001b[A\n",
            "Get old param:  58%|█████▊    | 143/245 [01:57<00:11,  8.84tensors/s]\n",
            "Get old param:  59%|█████▉    | 145/245 [01:57<00:12,  7.80tensors/s]\n",
            "Set new param:  59%|█████▉    | 241/407 [01:57<00:10, 15.29tensors/s]\u001b[A\n",
            "Get old param:  61%|██████    | 149/245 [01:58<00:10,  9.54tensors/s]\n",
            "Get old param:  62%|██████▏   | 151/245 [01:58<00:11,  8.25tensors/s]\n",
            "Set new param:  62%|██████▏   | 251/407 [01:58<00:10, 15.55tensors/s]\u001b[A\n",
            "Get old param:  63%|██████▎   | 155/245 [01:58<00:09,  9.93tensors/s]\n",
            "Get old param:  64%|██████▍   | 157/245 [01:59<00:10,  8.31tensors/s]\n",
            "Set new param:  64%|██████▍   | 261/407 [01:59<00:09, 15.23tensors/s]\u001b[A\n",
            "Get old param:  66%|██████▌   | 161/245 [01:59<00:08,  9.96tensors/s]\n",
            "Get old param:  67%|██████▋   | 163/245 [01:59<00:09,  8.40tensors/s]\n",
            "Set new param:  67%|██████▋   | 271/407 [01:59<00:08, 15.26tensors/s]\u001b[A\n",
            "Get old param:  68%|██████▊   | 167/245 [01:59<00:07,  9.99tensors/s]\n",
            "Get old param:  69%|██████▉   | 169/245 [02:00<00:09,  8.43tensors/s]\n",
            "Set new param:  69%|██████▉   | 281/407 [02:00<00:08, 15.16tensors/s]\u001b[A\n",
            "Get old param:  71%|███████   | 173/245 [02:00<00:07,  9.99tensors/s]\n",
            "Get old param:  71%|███████▏  | 175/245 [02:00<00:08,  8.47tensors/s]\n",
            "Set new param:  71%|███████▏  | 291/407 [02:01<00:07, 15.29tensors/s]\u001b[A\n",
            "Get old param:  73%|███████▎  | 179/245 [02:01<00:06, 10.13tensors/s]\n",
            "Get old param:  74%|███████▍  | 181/245 [02:01<00:07,  8.57tensors/s]\n",
            "Set new param:  74%|███████▍  | 301/407 [02:01<00:06, 15.48tensors/s]\u001b[A\n",
            "Get old param:  76%|███████▌  | 186/245 [02:20<00:05, 10.19tensors/s]\n",
            "Set new param:  76%|███████▌  | 308/407 [02:20<00:05, 17.05tensors/s]\u001b[A\n",
            "Get old param:  76%|███████▋  | 187/245 [02:29<02:57,  3.06s/tensors]\n",
            "Set new param:  76%|███████▋  | 311/407 [02:30<03:07,  1.95s/tensors]\u001b[A\n",
            "Get old param:  78%|███████▊  | 191/245 [02:30<01:44,  1.93s/tensors]\n",
            "Get old param:  79%|███████▉  | 193/245 [02:30<01:21,  1.56s/tensors]\n",
            "Set new param:  79%|███████▉  | 321/407 [02:30<01:01,  1.40tensors/s]\u001b[A\n",
            "Get old param:  80%|████████  | 197/245 [02:30<00:47,  1.00tensors/s]\n",
            "Get old param:  81%|████████  | 199/245 [02:31<00:37,  1.21tensors/s]\n",
            "Set new param:  82%|████████▏ | 332/407 [02:31<00:19,  3.80tensors/s]\u001b[A\n",
            "Get old param:  83%|████████▎ | 203/245 [02:31<00:22,  1.86tensors/s]\n",
            "Get old param:  84%|████████▎ | 205/245 [02:31<00:18,  2.16tensors/s]\n",
            "Set new param:  84%|████████▍ | 342/407 [02:31<00:08,  7.63tensors/s]\u001b[A\n",
            "Get old param:  85%|████████▌ | 209/245 [02:32<00:11,  3.20tensors/s]\n",
            "Get old param:  86%|████████▌ | 211/245 [02:32<00:09,  3.52tensors/s]\n",
            "Set new param:  86%|████████▋ | 352/407 [02:32<00:04, 11.82tensors/s]\u001b[A\n",
            "Get old param:  88%|████████▊ | 215/245 [02:32<00:06,  4.95tensors/s]\n",
            "Get old param:  89%|████████▊ | 217/245 [02:33<00:05,  4.97tensors/s]\n",
            "Set new param:  89%|████████▊ | 361/407 [02:33<00:03, 13.06tensors/s]\u001b[A\n",
            "Get old param:  90%|█████████ | 221/245 [02:33<00:03,  6.64tensors/s]\n",
            "Get old param:  91%|█████████ | 223/245 [02:33<00:03,  6.33tensors/s]\n",
            "Set new param:  91%|█████████ | 371/407 [02:33<00:02, 14.57tensors/s]\u001b[A\n",
            "Get old param:  93%|█████████▎| 227/245 [02:34<00:02,  8.08tensors/s]\n",
            "Get old param:  93%|█████████▎| 229/245 [02:34<00:02,  7.28tensors/s]\n",
            "Set new param:  94%|█████████▎| 381/407 [02:34<00:01, 15.05tensors/s]\u001b[A\n",
            "Get old param:  95%|█████████▌| 233/245 [02:34<00:01,  9.01tensors/s]\n",
            "Get old param:  96%|█████████▌| 235/245 [02:35<00:01,  7.86tensors/s]\n",
            "Set new param:  96%|█████████▋| 392/407 [02:35<00:00, 16.21tensors/s]\u001b[A\n",
            "Get old param:  98%|█████████▊| 239/245 [02:35<00:00,  9.58tensors/s]\n",
            "Get old param:  98%|█████████▊| 241/245 [02:35<00:00,  8.23tensors/s]\n",
            "Set new param:  99%|█████████▉| 402/407 [02:35<00:00, 16.23tensors/s]\u001b[A\n",
            "Set new param: 100%|█████████▉| 406/407 [02:35<00:00, 20.07tensors/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finish computing and quantizing weights.\n",
            "Total param size: 6.820138931274414 GB\n",
            "Start storing to cache dist/Llama-2-13b-chat-hf-q4f16_1/params\n",
            "[0176/0407] saving param_175"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Set new param: 100%|██████████| 407/407 [02:50<00:00, 20.07tensors/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0407/0407] saving param_406\n",
            "All finished, 163 total shards committed, record saved to dist/Llama-2-13b-chat-hf-q4f16_1/params/ndarray-cache.json\n",
            "Finish exporting chat config to dist/Llama-2-13b-chat-hf-q4f16_1/params/mlc-chat-config.json\n",
            "Save a cached module to dist/Llama-2-13b-chat-hf-q4f16_1/mod_cache_before_build.pkl.\n",
            "Finish exporting to dist/Llama-2-13b-chat-hf-q4f16_1/Llama-2-13b-chat-hf-q4f16_1-cuda.so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content Generation"
      ],
      "metadata": {
        "id": "x3OWz2C8g916"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directly use the returned paths to launch `ChatModule`\n",
        "chat_mod = mlc_chat.ChatModule(model=model_path)"
      ],
      "metadata": {
        "id": "xtO-NmxpWqkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Write me a poem about the city Pittsburgh\"\n",
        "chat_mod.generate(prompt=prompt)"
      ],
      "metadata": {
        "id": "rWhgHdNXXHW5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}